---
title: "Metabolomics_data_preprocessing"
author: "Prymidis Dimitrios"
date: "6/24/2021"
output: 
  html_document:
    toc: true
    number_sections: true
---

Load libraries 

```{r setup, include=FALSE, echo=TRUE, results = 'hide'}
knitr::opts_chunk$set(
  echo = FALSE, warning=FALSE, message = FALSE
)
library(readr)
library(tidyverse)
library(reshape2)
library(scales)
library(factoextra) # for PCA
```

Load metabolomics raw data files

# Polar positive,


```{r}
setwd("~/Documents/Int2/Project")
data <- read_csv("Data/raw/210617_Tomato_polar_positive_1000_noGC_raw_annotated.csv")
```

These are raw files

I will rewrite the colnames by hand.
```{r}
names <- c('Bucket_label','RT','m/z','Name','Formula','wt_ypi_d2_1', 'wt_ypi_d2_2', 'wt_ypi_d2_3','wt_ypi_d3_1','wt_ypi_d3_2','wt_ypi_d3_3','wt_ypi_d4_1','wt_ypi_d4_2','wt_ypi_d4_3', 'wt_ypi_d5_1','wt_ypi_d5_2','wt_ypi_d5_3','wt_npi_d2_1','wt_npi_d2_2','wt_npi_d2_3','wt_npi_d3_1','wt_npi_d3_2','wt_npi_d3_3','wt_npi_d4_1','wt_npi_d4_2','wt_npi_d4_3','wt_npi_d5_1' ,'wt_npi_d5_2','wt_npi_d5_3', 'ccd8_ypi_d4_1','ccd8_ypi_d4_2','ccd8_npi_d4_1','ccd8_npi_d4_2','ccd8_npi_d4_3','wt_rep_d5_1','wt_rep_d5_2','wt_rep_d5_3')
colnames(data) <- names

```

prepare the data
```{r}
# take only the numbers
tempnames <- data$Bucket_label # take feature names
tempnames <- tempnames[-1:-3] # remove non features

prefilt.data<- data %>% select(-'Bucket_label',-'RT',-'m/z',-'Name',-'Formula') %>% slice(-(1:3)) # take only the "numbers"
options(digits=15)
prefilt.data <-as.data.frame(lapply(prefilt.data,as.numeric)) # make it numeric 
rownames(prefilt.data) <- tempnames # add the feature names as rownames

# select only ctrl vs pdef columns
prefilt.data <- prefilt.data[,1:24]
```


First, you should filter the data
removing all feature that are not shared with at least 2 of the three replicates for at least one treatment.

i.e.
if a feature is >0 for only one of the 32 samples, remove it;
if a feature is >0 in two samples but not from a same treatment (for # example wt_d2_ypi), remove it
if a feature is present in only two samples from a sample treatment but not present for other treatment, keep # it
if a feature is present in 5 samples, 2 replicates from a same treatment and one replicate from 3 other treatment, keep it. 

Remove features that do not appear in triplicates
```{r}
remfeat<- c()

k<- seq(1:10)
for (i in k){

a<- prefilt.data[rowSums(prefilt.data == 0) == 24-i, ] # ckeck each time how many zeros a feature has in the 32 samples

if (dim(a)[1] ==0) { # if there are not features 
  print("**working**")
} else { # if there are

feat <- rownames(a) # save feature names

temp<- a # save the df
temp<-as.data.frame(temp>0) # make values into boolean
temp<-as.data.frame(lapply(temp, as.numeric)) # back to numeric to make it 0s and 1s
temp<- t(temp)
temp <- as.data.frame(temp)

b <- colnames(a)
b <- b %>% substring(1,9) 
temp$e<- b

melted <- melt(temp, id.vars=c("e")) # make the groups 
dff<- melted %>% group_by(e, variable) %>% # make a dataframe to save the values
  summarise(count=sum(value)) 

c<- dff[dff$count>1,2] # and get the names to keep that has more than 2 appearances

if (dim(c)[1] ==0) { # if no values appear the take all the feature names
  remfeat<- append(remfeat, feat)
} else {
  
d<- c$variable # take the feature
e<- d %>% substring(2,4)  %>% unique() # make it a number
e<- as.numeric(e)
remfeat<- append(remfeat, feat[-e]) # take all feature except that
}
}
}

data.filtered<- prefilt.data[!rownames(prefilt.data) %in% remfeat,] # remove all the saved features
features<- rownames(data.filtered)
```


# Data properties

## data dimensions

```{r}
dim(data.filtered)
```

We have: `r dim(data.filtered)[2]` variables and `r dim(data.filtered)[1]` features.


## Sparsity of the data
We will  assess the sparsity of the data frame counting the percentage of zeros. 

```{r}
sparsity <- sum(data.filtered == 0)/(dim(data.filtered)[1]*dim(data.filtered)[2])
print(sparsity)
```

Our data are not sparse.

## Feature frequency among the samples.

```{r}
feat.freq.per.samp <- data.filtered != 0
feat.freq.per.samp.df <-rowSums(feat.freq.per.samp)/32
feat.freq.per.samp.df <- as.data.frame(feat.freq.per.samp.df)
colnames(feat.freq.per.samp.df) <- "freq"
```

```{r}
#first need to convert the columns to numeric 
feat.freq.per.samp.df <- apply(feat.freq.per.samp.df,2,as.numeric)

hist(feat.freq.per.samp.df, breaks = 10,main = "Feature frequency among samples", xlab = "sample fraction", ylab = "feature counts",) 
```

## Number of features per sample

```{r}
feat.per.samp <- data.filtered != 0
feat.per.samp.df<- as.data.frame(colSums(feat.per.samp))
colSums(feat.per.samp)
```

```{r}
#first need to convert the columns to numeric 
feat.per.samp.df <- apply(feat.per.samp.df,2,as.numeric)
hist(feat.per.samp.df, breaks = 10,main = "Number of features per sample", xlab = "feature counts", ylab = "sample counts",) 
```

wt_npi_d2_1 has very few features. In order to decide if it is to be removed we will check the samples with PCA

## PCA

```{r}
pcadata<- as.data.frame(t(data.filtered))
res.pca <- prcomp(pcadata)
fviz_eig(res.pca)

fviz_pca_ind(res.pca,
             col.ind = "contrib", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

res.ind <- get_pca_ind(res.pca)
res.ind$coord          # Coordinates
res.ind$contrib        # Contributions to the PCs
res.ind$cos2           # Quality of representation 
ind.coord <- res.pca$x
head(ind.coord[, 1:4])
# Contributions of individuals
#:::::::::::::::::::::::::::::::
contrib <- function(ind.coord, comp.sdev, n.ind){
  100*(1/n.ind)*ind.coord^2/comp.sdev^2
}
ind.contrib <- t(apply(ind.coord, 1, contrib, 
                       res.pca$sdev, nrow(ind.coord)))
ind.contrib[13,]
```

Based on the PCA plot I remove the wt_npi_d2_1 samples.

There might be a problem with messing triplicates. We calculate fake ones using the mean of the two others. 

this is done for the samples 

for polar positive : ccd8_ypi_d4_3 (missing) and wt_npi_d2_1 (outlier) 

```{r}
#and for apolar pos: wt_rep_d5_3 
#for apolar negative: ccd8_ypi_d4_2

#data.filtered$ccd8_ypi_d4_3 <-rowMeans(cbind(data.filtered$ccd8_ypi_d4_2, data.filtered$ccd8_ypi_d4_1))
data.filtered$wt_npi_d2_1 <-rowMeans(cbind(data.filtered$wt_npi_d2_3,data.filtered$wt_npi_d2_3))
features<- rownames(data.filtered)
```

Check again the samples with PCA
```{r}
pcadata<- as.data.frame(t(data.filtered))
res.pca <- prcomp(pcadata) #, center = T, scale. = T)
fviz_eig(res.pca)

fviz_pca_ind(res.pca,
             col.ind = "contrib", # cos2 for Color by the quality of representation or contrib for contribution
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
            , #labels = FALSE
            )
```

## Distribution of the fittered data

```{r}
#easiest way

#first need to convert the columns to numeric 
data.filtered <- apply(data.filtered,2,as.numeric)


hist(data.filtered, breaks = 1000,main = "Count Distribution")#, xlim = c(0,50000)) 
#hist(data.filtered, breaks = 5000,main = "Count Distribution", xlim = c(0,20000)) 
```

```{r}
data.filtered.melt <- melt(data.filtered)
colnames(data.filtered.melt)[3] <- "Concentration"
#prettier 

ggplot(data.filtered.melt, aes(x = Concentration)) + geom_density(alpha = 0.5)+
    scale_y_continuous(labels = percent_format()) + theme_bw()+
    ggtitle("Count Distribution") #+xlim(c(0, 15000))
#  ggsave(paste0(Sys.Date(),"Coexpression_task2/Variance_stabilised_Distribution.pdf"), plot = plot)

```


## remove smaples with zeros
```{r}
temp<- as.data.frame(t(data.filtered))

```

# Check homoscedasticity of filtered data
(plot mean vs sd per treatment, so 11 treatments in total for each features = 11xnbfeature dots in your plot)

by plotting the standard deviation as a function of the mean of the three replicates for each treatment and feature
```{r}
tempdata<- as.data.frame(t(data.filtered))
tempdata$treatment <- rownames(tempdata)
tempdata$treatment <- sapply(tempdata$treatment, function(x){substring(x, 1, 9)})

melted <- melt(tempdata, id.vars=c("treatment")) # make the groups 

melted <- melted %>% filter(value != 0)# remove all 0 rows

grouped <- group_by(melted, treatment)

sceddata<- melted %>% group_by(treatment, variable) %>% # make a dataframe to save the values
  summarise(mean=mean(value), sd=sd(value)) 

sceddata<- na.omit(sceddata)
sceddata<- sceddata[is.finite(sceddata$sd),]

#plot(x=sceddata$mean, y=sceddata$sd, log='xy', pch=20, cex=0.5, # plot the mean vs sd
 #    xlab='Mean rate', ylab='Standard deviation')


# GGplot separated heteroscedasticity check on filtered data data

#first need to separate treatment column into genotypeXtreatment and time

sceddata <- as.data.frame(sceddata)
sceddata$treatment <- gsub("_$","_d4",sceddata$treatment)

#just to make sure we have the original column
sceddata$condition <- sceddata$treatment

sceddata$timepoint <- gsub(".*_","",sceddata$treatment)
sceddata$treatment <- gsub("_d.*","",sceddata$treatment)

ggplot(sceddata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw() + geom_abline(intercept = 0)  #+ geom_smooth(aes(group=lala),method='lm', formula= y~x, color = "red")

sceddata$lala <- 1

ggplot(sceddata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw() + 
  scale_x_continuous(trans='log2',  limits = c(1,500000)) +
  scale_y_continuous(trans='log2',  limits = c(1,500000)) + xlab("log(mean)") + ylab("log(sd)") + geom_abline(intercept = 0)  + ggtitle("preprocessed data")  + geom_smooth(aes(group=lala),method='lm', formula= y~x, color = "red")

```

as the mean grows the sd also grows which means the data are heteroscedastic so we have to transform them

## sqrt Data transformation

try different transformation square root, log, vst other? and check again homoscedasticity
```{r}
data.sqrt<- sqrt(data.filtered)

tempdata<- as.data.frame(t(data.sqrt))
tempdata$treatment <- rownames(tempdata)
tempdata$treatment <- sapply(tempdata$treatment, function(x){substring(x, 1, 9)})

melted <- melt(tempdata, id.vars=c("treatment")) # make the groups 
melted <- melted %>% filter(value != 0)# remove all 0 rows
grouped <- group_by(melted, treatment)

sqrtdata<- melted %>% group_by(treatment, variable) %>% # make a dataframe to save the values
  summarise(mean=mean(value), sd=sd(value)) 

sqrtdata<- na.omit(sqrtdata)
sqrtdata<- sqrtdata[is.finite(sqrtdata$sd),]

#plot(x=sqrtdata$mean, y=sqrtdata$sd, log='xy', pch=20, cex=0.5, # plot the mean vs sd
#     xlab='Mean rate', ylab='Standard deviation')


# GGplot separated heteroscedasticity check on filtered data data 

#first need to separate treatment column into genotypeXtreatment and time

sqrtdata <- as.data.frame(sqrtdata)
sqrtdata$treatment <- gsub("_$","_d4",sqrtdata$treatment)

#just to make sure we have the original column
sqrtdata$condition <- sqrtdata$treatment

sqrtdata$timepoint <- gsub(".*_","",sqrtdata$treatment)
sqrtdata$treatment <- gsub("_d.*","",sqrtdata$treatment)

ggplot(sqrtdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()  

sqrtdata$lala <- 1

ggplot(sqrtdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()    +   scale_x_continuous(trans='log2', limits = c(1,1000)) +
  scale_y_continuous(trans='log2', limits = c(1,100))+ xlab("log(mean)") + ylab("log(sd)") + geom_abline(intercept = 0)  + ggtitle("square root transformation ") + geom_smooth(aes(group=lala),method='lm', formula= y~x, color = "red")
```

Distribution of the sqrt data

```{r}
#easiest way

#first need to convert the columns to numeric 
data.sqrt <- apply(data.sqrt,2,as.numeric)

#hist(data.sqrt, breaks = 100,main = "Count Distribution", xlim = c(0,400))  # 

data.sqrt <- melt(data.sqrt)
colnames(data.sqrt)[3] <- "Concentration"
#prettier 

ggplot(data.sqrt, aes(x = Concentration)) + geom_density(alpha = 0.5)+
    scale_y_continuous(labels = percent_format()) + theme_bw()+
    ggtitle("Count Distribution") + xlim(c(0, 300))
#  ggsave(paste0(Sys.Date(),"Coexpression_task2/Variance_stabilised_Distribution.pdf"), plot = plot)

```


## log Data transformation

```{r}
data.log<- log(data.filtered + 1 )  # change inf to zero

tempdata<- as.data.frame(t(data.log))
tempdata$treatment <- rownames(tempdata)
tempdata$treatment <- sapply(tempdata$treatment, function(x){substring(x, 1, 9)})

melted <- melt(tempdata, id.vars=c("treatment")) # make the groups 
melted <- melted %>% filter(value != 0)# remove all 0 rows
grouped <- group_by(melted, treatment)

logdata<- melted %>% group_by(treatment, variable) %>% # make a dataframe to save the values
  summarise(mean=mean(value), sd=sd(value)) 

logdata<- na.omit(logdata)
logdata<- logdata[is.finite(logdata$sd),]

# plot(x=logdata$mean, y=logdata$sd, log='xy', pch=20, cex=0.5, # plot the mean vs sd
#     xlab='Mean rate', ylab='Standard deviation')

# for ggplot
#first need to separate treatment column into genotypeXtreatment and time

logdata <- as.data.frame(logdata)
logdata$treatment <- gsub("_$","_d4",logdata$treatment)

#just to make sure we have the original column
logdata$condition <- logdata$treatment

logdata$timepoint <- gsub(".*_","",logdata$treatment)
logdata$treatment <- gsub("_d.*","",logdata$treatment)

ggplot(logdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()  
ggplot(logdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()    +  scale_x_continuous(trans='log2') +
  scale_y_continuous(trans='log2') + xlab("log(mean)") + ylab("log(sd)")

logdata$lala <- 1

ggplot(logdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()    +  scale_x_continuous(trans='log2', limits = c(1,10)) +
  scale_y_continuous(trans='log2', limits = c(1,10)) + xlab("log(mean)") + ylab("log(sd)") + geom_abline(intercept = 0)  +ggtitle("logarithmic transformation ")+ geom_smooth(aes(group=lala),method='lm', formula= y~x, color = "red")

```

Distribution of the log data

```{r}
#easiest way

#first need to convert the columns to numeric 
data.log <- apply(data.log,2,as.numeric)

#hist(data.log, breaks = 100,main = "Count Distribution") 

data.log <- melt(data.log)
colnames(data.log)[3] <- "Concentration"
#prettier 

ggplot(data.log, aes(x = Concentration)) + geom_density(alpha = 0.5)+
    scale_y_continuous(labels = percent_format()) + theme_bw()+
    ggtitle("Count Distribution")
#  ggsave(paste0(Sys.Date(),"Coexpression_task2/Variance_stabilised_Distribution.pdf"), plot = plot)

```

##  Variance stabilizing transformation

first we take the 50% of samples with highest mean
then we fit a line on the log of mean~sd
``` {r}
# try t take values from 0.5 to 1l 
#temp <- sceddata %>% arrange(-mean)
#ocdata<- top_frac(temp, 0.5, mean)

ocdata<- sceddata
# make the data log
ocdata[,c(3,4)] <- log(sceddata[,c(3,4)])
ocdata<- na.omit(ocdata)
ocdata<- ocdata[is.finite(ocdata$sd),]

data.fit <- lm(sd~mean, ocdata) # make the fit
coef(data.fit)
#plot(data.fit)

```

```{r}
temp <- sceddata
temp <- as.data.frame(temp)
temp$treatment <- gsub("_$","_d4",temp$treatment)

#just to make sure we have the original column
ocdata$condition <- ocdata$treatment

ocdata$timepoint <- gsub(".*_","",ocdata$treatment)
ocdata$treatment <- gsub("_d.*","",ocdata$treatment)

#ggplot(ocdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +  geom_point() + theme_bw()  
#ggplot(ocdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
#  geom_point() + theme_bw()    +  scale_x_continuous(trans='log2') +
#  scale_y_continuous(trans='log2') #+  geom_smooth(method='lm')
```

the slope equals  `r coef(data.fit)[2]` which means the sd depends strongly on the mean

transform the data using the optimal correction

```{r}
temp<- tempdata
temp$treatment <- NULL

data.vst <- as.data.frame(data.filtered^(1-coef(data.fit)['mean'][1]))



```

check homoscedastisity of vst transformation
```{r}

tempdata<- as.data.frame(t(data.vst))
tempdata$treatment <- rownames(tempdata)
tempdata$treatment <- sapply(tempdata$treatment, function(x){substring(x, 1, 9)})

melted <- melt(tempdata, id.vars=c("treatment")) # make the groups 
melted <- melted %>% filter(value != 0)# remove all 0 rows
grouped <- group_by(melted, treatment)

vstdata<- melted %>% group_by(treatment, variable) %>% # make a dataframe to save the values
  summarise(mean=mean(value), sd=sd(value)) 

vstdata<- na.omit(vstdata)
vstdata<- vstdata[is.finite(vstdata$sd),]

# plot(x=vstdata$mean, y=vstdata$sd, log='xy', pch=20, cex=0.5, # plot the mean vs sd
#     xlab='Mean rate', ylab='Standard deviation')

#first need to separate treatment column into genotypeXtreatment and time

vstdata <- as.data.frame(vstdata)
vstdata$treatment <- gsub("_$","_d4",vstdata$treatment)

#just to make sure we have the original column
vstdata$condition <- vstdata$treatment

vstdata$timepoint <- gsub(".*_","",vstdata$treatment)
vstdata$treatment <- gsub("_d.*","",vstdata$treatment)

ggplot(vstdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()  
ggplot(vstdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()    +  scale_x_continuous(trans='log2') +
  scale_y_continuous(trans='log2') + xlab("log(mean)") + ylab("log(sd)")  + geom_abline(intercept = 0)   +ggtitle("vst transformation ")

vstdata$group <- 1

ggplot(vstdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()    +  scale_x_continuous(trans='log2', limits = c(0.5,8)) +
  scale_y_continuous(trans='log2', limits = c(0.5,8)) + xlab("log(mean)") + ylab("log(sd)") + geom_abline(intercept = 0)  +ggtitle("Vst transformation ") + geom_smooth(aes(group=group),method='lm', formula= y~x, color = "red")

```

Distribution of the transformed data

```{r}
#easiest way

#first need to convert the columns to numeric 
data.vst <- apply(data.vst,2,as.numeric)

#hist(data.sqrt, breaks = 100,main = "Count Distribution", xlim = c(0,400))  # 

data.vst <- melt(data.vst)
colnames(data.vst)[3] <- "Concentration"
#prettier 

ggplot(data.vst, aes(x = Concentration)) + geom_density(alpha = 0.5)+
    scale_y_continuous(labels = percent_format()) + theme_bw()+
    ggtitle("Count Distribution") + xlim(c(0, 6))
#  ggsave(paste0(Sys.Date(),"Coexpression_task2/Variance_stabilised_Distribution.pdf"), plot = plot)

```


Decide transfotmation and save the data


```{r}
temp<- data.filtered
data.vst <- as.data.frame(temp^(1-coef(data.fit)['mean']))
rownames(data.vst) <- features
write.csv(data.vst,'Data/processed/metabolomics_polar_data_vst_new.csv') # save the table
```
make again the original table?


We are interested in the wt in ctrl vs Pdef conditions. So we only take the wt ypi and wt npi.


# Check if the lines are the zeros

Remove all rows with zeros and plot the mean and sd again
```{r}

#Go through each row and determine if a value is zero
row_sub = apply(data.filtered, 1, function(row) all(row !=0 ))
##Subset as usual
temp<- data.filtered[row_sub,]
sum(row_sub)
```

```{r}
tempdata<- as.data.frame(t(temp))
tempdata$treatment <- rownames(tempdata)
tempdata$treatment <- sapply(tempdata$treatment, function(x){substring(x, 1, 9)})

melted <- melt(tempdata, id.vars=c("treatment")) # make the groups 
grouped <- group_by(melted, treatment)

zdata<- melted %>% group_by(treatment, variable) %>% # make a dataframe to save the values
  summarise(mean=mean(value), sd=sd(value)) 

#plot(x=sceddata$mean, y=sceddata$sd, log='xy', pch=20, cex=0.5, # plot the mean vs sd
 #    xlab='Mean rate', ylab='Standard deviation')

#first need to separate treatment column into genotypeXtreatment and time

zdata <- as.data.frame(zdata)
zdata$treatment <- gsub("_$","_d4",zdata$treatment)

#just to make sure we have the original column
zdata$condition <- zdata$treatment

zdata$timepoint <- gsub(".*_","",zdata$treatment)
zdata$treatment <- gsub("_d.*","",zdata$treatment)

ggplot(zdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw()

ggplot(zdata, aes(x = mean, y = sd, shape = timepoint, colour = treatment)) +
  geom_point() + theme_bw() + 
  scale_x_continuous(trans='log2') +
  scale_y_continuous(trans='log2') + xlab("log(mean)") + ylab("log(sd)")

```

and lines are gone

Choose transformation 
```{r}
data.log<- log(data.filtered + 1 ) 
data.log <- as.data.frame(data.log)
rownames(data.log) <- features

#write.csv(data.log,'metabolomics_processed_log_transformed_polar_positive')

```

